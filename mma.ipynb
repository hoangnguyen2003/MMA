{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12790965,"sourceType":"datasetVersion","datasetId":8087066},{"sourceId":12809686,"sourceType":"datasetVersion","datasetId":8099873}],"dockerImageVersionId":30055,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/hoangnguyen2003/MMA.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T13:24:17.601760Z","iopub.execute_input":"2025-08-20T13:24:17.602182Z","iopub.status.idle":"2025-08-20T13:24:19.766664Z","shell.execute_reply.started":"2025-08-20T13:24:17.602092Z","shell.execute_reply":"2025-08-20T13:24:19.765893Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'MMA'...\nremote: Enumerating objects: 202, done.\u001b[K\nremote: Counting objects: 100% (30/30), done.\u001b[K\nremote: Compressing objects: 100% (20/20), done.\u001b[K\nremote: Total 202 (delta 17), reused 23 (delta 10), pack-reused 172 (from 1)\u001b[K\nReceiving objects: 100% (202/202), 954.00 KiB | 4.24 MiB/s, done.\nResolving deltas: 100% (110/110), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"cd /kaggle/working/MMA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T13:24:19.769120Z","iopub.execute_input":"2025-08-20T13:24:19.769503Z","iopub.status.idle":"2025-08-20T13:24:19.775733Z","shell.execute_reply.started":"2025-08-20T13:24:19.769462Z","shell.execute_reply":"2025-08-20T13:24:19.774194Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/MMA\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"conda create --name MMA python=3.7 -y","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-08-20T13:24:19.777132Z","iopub.execute_input":"2025-08-20T13:24:19.777455Z","iopub.status.idle":"2025-08-20T13:25:04.418989Z","shell.execute_reply.started":"2025-08-20T13:24:19.777423Z","shell.execute_reply":"2025-08-20T13:25:04.417957Z"}},"outputs":[{"name":"stdout","text":"Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.9.2\n  latest version: 25.7.0\n\nPlease update conda by running\n\n    $ conda update -n base conda\n\n\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/MMA\n\n  added / updated specs:\n    - python=3.7\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    _libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge\n    _openmp_mutex-4.5          |            2_gnu          23 KB  conda-forge\n    ca-certificates-2025.8.3   |       hbd8a1cb_0         151 KB  conda-forge\n    ld_impl_linux-64-2.44      |       h1423503_1         660 KB  conda-forge\n    libffi-3.4.6               |       h2dba641_1          56 KB  conda-forge\n    libgcc-15.1.0              |       h767d61c_4         805 KB  conda-forge\n    libgcc-ng-15.1.0           |       h69a702a_4          29 KB  conda-forge\n    libgomp-15.1.0             |       h767d61c_4         437 KB  conda-forge\n    liblzma-5.8.1              |       hb9d3cd8_2         110 KB  conda-forge\n    liblzma-devel-5.8.1        |       hb9d3cd8_2         430 KB  conda-forge\n    libnsl-2.0.1               |       hb9d3cd8_1          33 KB  conda-forge\n    libsqlite-3.50.4           |       h0c1763c_0         911 KB  conda-forge\n    libstdcxx-15.1.0           |       h8f9b012_4         3.7 MB  conda-forge\n    libstdcxx-ng-15.1.0        |       h4852527_4          29 KB  conda-forge\n    libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge\n    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n    openssl-3.5.2              |       h26f9b46_0         3.0 MB  conda-forge\n    pip-22.1.2                 |     pyhd8ed1ab_0         1.5 MB  conda-forge\n    python-3.7.12              |hf930737_100_cpython        57.3 MB  conda-forge\n    python_abi-3.7             |          4_cp37m           6 KB  conda-forge\n    readline-8.2               |       h8c095d6_2         276 KB  conda-forge\n    setuptools-65.3.0          |   py37h89c1867_0         1.4 MB  conda-forge\n    sqlite-3.50.4              |       hbc0de68_0         162 KB  conda-forge\n    tk-8.6.13                  |noxft_hd72426e_102         3.1 MB  conda-forge\n    wheel-0.41.3               |     pyhd8ed1ab_0          57 KB  conda-forge\n    xz-5.8.1                   |       hbcc6ac9_2          23 KB  conda-forge\n    xz-gpl-tools-5.8.1         |       hbcc6ac9_2          33 KB  conda-forge\n    xz-tools-5.8.1             |       hb9d3cd8_2          94 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        75.2 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu\n  ca-certificates    conda-forge/noarch::ca-certificates-2025.8.3-hbd8a1cb_0\n  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.44-h1423503_1\n  libffi             conda-forge/linux-64::libffi-3.4.6-h2dba641_1\n  libgcc             conda-forge/linux-64::libgcc-15.1.0-h767d61c_4\n  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.1.0-h69a702a_4\n  libgomp            conda-forge/linux-64::libgomp-15.1.0-h767d61c_4\n  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_2\n  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.8.1-hb9d3cd8_2\n  libnsl             conda-forge/linux-64::libnsl-2.0.1-hb9d3cd8_1\n  libsqlite          conda-forge/linux-64::libsqlite-3.50.4-h0c1763c_0\n  libstdcxx          conda-forge/linux-64::libstdcxx-15.1.0-h8f9b012_4\n  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-15.1.0-h4852527_4\n  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2\n  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3\n  openssl            conda-forge/linux-64::openssl-3.5.2-h26f9b46_0\n  pip                conda-forge/noarch::pip-22.1.2-pyhd8ed1ab_0\n  python             conda-forge/linux-64::python-3.7.12-hf930737_100_cpython\n  python_abi         conda-forge/linux-64::python_abi-3.7-4_cp37m\n  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2\n  setuptools         conda-forge/linux-64::setuptools-65.3.0-py37h89c1867_0\n  sqlite             conda-forge/linux-64::sqlite-3.50.4-hbc0de68_0\n  tk                 conda-forge/linux-64::tk-8.6.13-noxft_hd72426e_102\n  wheel              conda-forge/noarch::wheel-0.41.3-pyhd8ed1ab_0\n  xz                 conda-forge/linux-64::xz-5.8.1-hbcc6ac9_2\n  xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.8.1-hbcc6ac9_2\n  xz-tools           conda-forge/linux-64::xz-tools-5.8.1-hb9d3cd8_2\n\n\n\nDownloading and Extracting Packages\nliblzma-devel-5.8.1  | 430 KB    | ##################################### | 100% \nxz-5.8.1             | 23 KB     | ##################################### | 100% \nlibsqlite-3.50.4     | 911 KB    | ##################################### | 100% \nlibffi-3.4.6         | 56 KB     | ##################################### | 100% \ntk-8.6.13            | 3.1 MB    | ##################################### | 100% \n_libgcc_mutex-0.1    | 3 KB      | ##################################### | 100% \nsqlite-3.50.4        | 162 KB    | ##################################### | 100% \nncurses-6.5          | 871 KB    | ##################################### | 100% \nxz-gpl-tools-5.8.1   | 33 KB     | ##################################### | 100% \nlibstdcxx-ng-15.1.0  | 29 KB     | ##################################### | 100% \nlibzlib-1.3.1        | 60 KB     | ##################################### | 100% \npython-3.7.12        | 57.3 MB   | ##################################### | 100% \nca-certificates-2025 | 151 KB    | ##################################### | 100% \nliblzma-5.8.1        | 110 KB    | ##################################### | 100% \nreadline-8.2         | 276 KB    | ##################################### | 100% \nopenssl-3.5.2        | 3.0 MB    | ##################################### | 100% \nxz-tools-5.8.1       | 94 KB     | ##################################### | 100% \npython_abi-3.7       | 6 KB      | ##################################### | 100% \n_openmp_mutex-4.5    | 23 KB     | ##################################### | 100% \nlibgomp-15.1.0       | 437 KB    | ##################################### | 100% \nlibgcc-15.1.0        | 805 KB    | ##################################### | 100% \nlibstdcxx-15.1.0     | 3.7 MB    | ##################################### | 100% \nlibnsl-2.0.1         | 33 KB     | ##################################### | 100% \nlibgcc-ng-15.1.0     | 29 KB     | ##################################### | 100% \nsetuptools-65.3.0    | 1.4 MB    | ##################################### | 100% \npip-22.1.2           | 1.5 MB    | ##################################### | 100% \nld_impl_linux-64-2.4 | 660 KB    | ##################################### | 100% \nwheel-0.41.3         | 57 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate MMA\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!source activate MMA && pip install -r requirements.txt","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-08-20T13:25:04.420854Z","iopub.execute_input":"2025-08-20T13:25:04.421260Z","iopub.status.idle":"2025-08-20T13:36:18.552050Z","shell.execute_reply.started":"2025-08-20T13:25:04.421215Z","shell.execute_reply":"2025-08-20T13:36:18.550976Z"}},"outputs":[{"name":"stdout","text":"Error in sitecustomize; set PYTHONVERBOSE for traceback:\nModuleNotFoundError: No module named 'google'\nCollecting absl-py==1.3.0\n  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m698.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting accelerate==0.20.3\n  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting aiohttp==3.8.6\n  Downloading aiohttp-3.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (987 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m988.0/988.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting aiosignal==1.3.1\n  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\nCollecting appdirs==1.4.4\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nCollecting async-timeout==4.0.3\n  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nCollecting asynctest==0.13.0\n  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\nCollecting attrs==23.1.0\n  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting audioread==3.0.1\n  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\nCollecting backcall==0.2.0\n  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\nCollecting bitsandbytes==0.43.3\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting black==23.3.0\n  Downloading black-23.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting boto3==1.21.37\n  Downloading boto3-1.21.37-py3-none-any.whl (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting botocore==1.24.37\n  Downloading botocore-1.24.37-py3-none-any.whl (8.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hCollecting Bottleneck\n  Downloading Bottleneck-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.9/355.9 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Brotli==1.1.0\n  Downloading Brotli-1.1.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting cachetools==5.2.0\n  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\nCollecting certifi==2021.10.8\n  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cffi==1.15.1\n  Downloading cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.9/427.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting charset-normalizer==2.0.12\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting click==8.1.2\n  Downloading click-8.1.2-py3-none-any.whl (96 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cmake==3.22.3\n  Downloading cmake-3.22.3-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hCollecting colorama==0.4.5\n  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\nCollecting coloredlogs==15.0.1\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cycler==0.11.0\n  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\nCollecting datasets==2.13.2\n  Downloading datasets-2.13.2-py3-none-any.whl (512 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m990.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting decorator==5.1.1\n  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\nCollecting dill==0.3.6\n  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting dlib==19.23.1\n  Downloading dlib-19.23.1.tar.gz (7.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting docker-pycreds==0.4.0\n  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\nCollecting exceptiongroup==1.1.3\n  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\nCollecting face-recognition==1.2.3\n  Downloading face_recognition-1.2.3-py2.py3-none-any.whl (21 kB)\nCollecting face-recognition-models==0.3.0\n  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting facenet-pytorch==0.4.0\n  Downloading facenet_pytorch-0.4.0-py3-none-any.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:00:01\u001b[0m\n\u001b[?25hCollecting filelock==3.6.0\n  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\nCollecting fire==0.5.0\n  Downloading fire-0.5.0.tar.gz (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting fonttools==4.38.0\n  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting frozenlist==1.3.3\n  Downloading frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fsspec==2023.1.0\n  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting gensim==4.2.0\n  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting gitdb==4.0.10\n  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting GitPython==3.1.31\n  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting google-auth==2.13.0\n  Downloading google_auth-2.13.0-py2.py3-none-any.whl (174 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting google-auth-oauthlib==0.4.6\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nCollecting grpcio==1.50.0\n  Downloading grpcio-1.50.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting h5py==3.7.0\n  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting huggingface-hub==0.16.4\n  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting humanfriendly==10.0\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting idna==3.3\n  Downloading idna-3.3-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting importlib-metadata==4.11.3\n  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\nCollecting inflate64==0.3.1\n  Downloading inflate64-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting iniconfig==2.0.0\n  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\nCollecting ipdb==0.13.9\n  Downloading ipdb-0.13.9.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ipython==7.34.0\n  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jedi==0.18.1\n  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jmespath==1.0.0\n  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\nCollecting joblib==1.1.0\n  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting kiwisolver==1.4.4\n  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting lazy_loader==0.3\n  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\nCollecting librosa==0.10.1\n  Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting llvmlite==0.39.1\n  Downloading llvmlite-0.39.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting loralib==0.1.2\n  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\nCollecting Markdown==3.4.1\n  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting MarkupSafe==2.1.1\n  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting matplotlib==3.5.3\n  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting matplotlib-inline==0.1.6\n  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\nCollecting mkl-fft==1.3.1\n  Downloading mkl_fft-1.3.1-16-cp37-cp37m-manylinux2014_x86_64.whl (241 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.6/241.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mkl-random\n  Downloading mkl_random-1.2.2-16-cp37-cp37m-manylinux2014_x86_64.whl (379 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.4/379.4 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mkl-service==2.4.0\n  Downloading mkl_service-2.4.0-11-cp37-cp37m-manylinux2014_x86_64.whl (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mpmath==1.3.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting msgpack==1.0.5\n  Downloading msgpack-1.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.7/299.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting multidict==6.0.4\n  Downloading multidict-6.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting multiprocess==0.70.14\n  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting multivolumefile==0.2.3\n  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nCollecting mypy-extensions==1.0.0\n  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\nCollecting numba==0.56.4\n  Downloading numba-0.56.4-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting numexpr\n  Downloading numexpr-2.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (382 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.1/382.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy\n  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-ml-py==11.515.0\n  Downloading nvidia_ml_py-11.515.0-py3-none-any.whl (28 kB)\nCollecting oauthlib==3.2.2\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting optimum==1.14.0\n  Downloading optimum-1.14.0-py3-none-any.whl (398 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.9/398.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting packaging==23.2\n  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pandas==1.3.4\n  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting parso==0.8.3\n  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pathspec==0.11.2\n  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\nCollecting pathtools==0.1.2\n  Downloading pathtools-0.1.2.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting peft==0.3.0\n  Downloading peft-0.3.0-py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pexpect==4.8.0\n  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pickleshare==0.7.5\n  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\nCollecting Pillow==9.0.1\n  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting platformdirs==4.0.0\n  Downloading platformdirs-4.0.0-py3-none-any.whl (17 kB)\nCollecting pluggy==1.2.0\n  Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\nCollecting pooch==1.8.0\n  Downloading pooch-1.8.0-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting prompt-toolkit==3.0.31\n  Downloading prompt_toolkit-3.0.31-py3-none-any.whl (382 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.3/382.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting protobuf==3.19.6\n  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting psutil==5.9.4\n  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting ptyprocess==0.7.0\n  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\nCollecting py7zr==0.20.6\n  Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyarrow==12.0.1\n  Downloading pyarrow-12.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.1/39.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pyasn1==0.4.8\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyasn1-modules==0.2.8\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pybcj==1.0.1\n  Downloading pybcj-1.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pycparser==2.21\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pycryptodomex==3.19.0\n  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Pygments==2.13.0\n  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyparsing==3.0.9\n  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyppmd==1.0.0\n  Downloading pyppmd-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.6/138.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytest==7.4.3\n  Downloading pytest-7.4.3-py3-none-any.whl (325 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.1/325.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-dateutil\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytorch-transformers==1.0.0\n  Downloading pytorch_transformers-1.0.0-py3-none-any.whl (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytz==2022.1\n  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting PyYAML==6.0\n  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyzstd==0.15.9\n  Downloading pyzstd-0.15.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (410 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting regex==2022.3.15\n  Downloading regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.6/749.6 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests==2.27.1\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests-oauthlib==1.3.1\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting rsa==4.9\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting s3transfer==0.5.2\n  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sacremoses==0.0.49\n  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting safetensors==0.4.0\n  Downloading safetensors-0.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scikit-learn==0.21.3\n  Downloading scikit_learn-0.21.3-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0mm\n\u001b[?25hCollecting scipy==1.3.1\n  Downloading scipy-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/25.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting sentencepiece==0.1.96\n  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:00:01\u001b[0m\n\u001b[?25hCollecting sentry-sdk==1.16.0\n  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting setproctitle==1.3.2\n  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\nCollecting six\n  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nCollecting smart-open==6.0.0\n  Downloading smart_open-6.0.0-py3-none-any.whl (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting smmap==5.0.0\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\nCollecting soundfile==0.12.1\n  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting soxr==0.3.7\n  Downloading soxr-0.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sympy==1.10.1\n  Downloading sympy-1.10.1-py3-none-any.whl (6.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting tensorboard==2.10.1\n  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting tensorboard-data-server==0.6.1\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting tensorboard-plugin-wit==1.8.1\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorboardX==2.5.1\n  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting termcolor==2.3.0\n  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\nCollecting texttable==1.7.0\n  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\nCollecting tokenize-rt==5.0.0\n  Downloading tokenize_rt-5.0.0-py2.py3-none-any.whl (5.8 kB)\nCollecting tokenizers==0.13.3\n  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hCollecting toml==0.10.2\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nCollecting tomli==2.0.1\n  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\nCollecting torch==1.13.1\n  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m675.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio\n  Downloading torchaudio-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (4.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision\n  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tqdm==4.64.1\n  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting traitlets==5.4.0\n  Downloading traitlets-5.4.0-py3-none-any.whl (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting transformers==4.30.2\n  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting typed-ast==1.5.5\n  Downloading typed_ast-1.5.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (778 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.3/778.3 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typing_extensions==4.7.1\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nCollecting urllib3==1.26.14\n  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting validators==0.20.0\n  Downloading validators-0.20.0.tar.gz (30 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting wandb==0.13.10\n  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting wcwidth==0.2.5\n  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\nCollecting Werkzeug==2.2.2\n  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xxhash==3.4.1\n  Downloading xxhash-3.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting yarl==1.9.2\n  Downloading yarl-1.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.2/236.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting zipp==3.8.0\n  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\nRequirement already satisfied: setuptools in /opt/conda/envs/MMA/lib/python3.7/site-packages (from ipdb==0.13.9->-r requirements.txt (line 53)) (65.3.0)\nCollecting dpcpp_cpp_rt\n  Downloading dpcpp_cpp_rt-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (34 kB)\nCollecting mkl\n  Downloading mkl-2024.2.2-py2.py3-none-manylinux1_x86_64.whl (195.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.5/195.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: wheel in /opt/conda/envs/MMA/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->-r requirements.txt (line 79)) (0.41.3)\nCollecting intel-sycl-rt==2024.2.1\n  Downloading intel_sycl_rt-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (10.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m0m\n\u001b[?25hCollecting intel-opencl-rt==2024.2.1\n  Downloading intel_opencl_rt-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (201.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.2/201.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hCollecting intel-openmp==2024.2.1\n  Downloading intel_openmp-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (29.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.6/29.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tbb==2021.*\n  Downloading tbb-2021.13.1-py2.py3-none-manylinux1_x86_64.whl (5.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting intel-cmplr-lic-rt==2024.*\n  Downloading intel_cmplr_lic_rt-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (19 kB)\nCollecting intel-cmplr-lib-ur==2024.2.1\n  Downloading intel_cmplr_lib_ur-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (5.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting intel-cmplr-lib-rt==2024.2.1\n  Downloading intel_cmplr_lib_rt-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (45.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'nvidia-ml-py' candidate (version 11.515.0 at https://files.pythonhosted.org/packages/1b/ed/0be2dc05391e2ab43a07be0b0c9e068f70eb9811ab6b1d407c9c3f245d32/nvidia_ml_py-11.515.0-py3-none-any.whl#sha256=f0b9295adfa82c57202520b86caa9d1b319292a8caed5b95646ac46c6f28405e (from https://pypi.org/simple/nvidia-ml-py/))\nReason for being yanked: Not yet ready\u001b[0m\u001b[33m\n\u001b[0mBuilding wheels for collected packages: dlib, face-recognition-models, fire, ipdb, pathtools, validators\n  Building wheel for dlib (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for dlib: filename=dlib-19.23.1-cp37-cp37m-linux_x86_64.whl size=3853055 sha256=52f51f66dc8a7502c142cdd818dd51d535710608cae2ad7ee2042ad2d6dbd83c\n  Stored in directory: /root/.cache/pip/wheels/93/53/52/4c69731d478f8cffde23a24f3b8a04e6ab9fe49848026deecd\n  Building wheel for face-recognition-models (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=7f80c0dcb1723d8ffd242f076c6c128b0cdac1c57e25564e8f967184d1be838f\n  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116933 sha256=84f223f23064881108f5085dec1178d110fbbf72e42982a4e10de24d81144ae7\n  Stored in directory: /root/.cache/pip/wheels/20/97/e1/dd2c472bebcdcaa85fdc07d0f19020299f1c86773028860c53\n  Building wheel for ipdb (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ipdb: filename=ipdb-0.13.9-py3-none-any.whl size=11626 sha256=4cc6d31ce6e1b3ec35c48fa4d4d057e4a5f4fdffa735642b836cfd981f9ea3e1\n  Stored in directory: /root/.cache/pip/wheels/65/cd/cc/aaf92acae337a28fdd2aa4d632196a59745c8c39f76eaeed01\n  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8790 sha256=1e5edec50c231a031c5c5736c8985188877faf5c6a1f1448639f2ea157231910\n  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n  Building wheel for validators (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19573 sha256=50df1c0ae1de9252785ec4cde8a986f0a17fb60fcac556b629c9d8abf9ab7952\n  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\nSuccessfully built dlib face-recognition-models fire ipdb pathtools validators\nInstalling collected packages: wcwidth, tokenizers, texttable, tensorboard-plugin-wit, tbb, sentencepiece, pytz, pyasn1, ptyprocess, pickleshare, pathtools, nvidia-ml-py, msgpack, mpmath, intel-cmplr-lic-rt, intel-cmplr-lib-ur, intel-cmplr-lib-rt, face-recognition-models, dlib, cmake, certifi, Brotli, backcall, appdirs, zipp, xxhash, urllib3, typing_extensions, typed-ast, traitlets, tqdm, tomli, toml, tokenize-rt, termcolor, tensorboard-data-server, sympy, smmap, smart-open, six, setproctitle, safetensors, rsa, regex, pyzstd, PyYAML, pyppmd, pyparsing, Pygments, pycryptodomex, pycparser, pyasn1-modules, psutil, protobuf, prompt-toolkit, Pillow, pexpect, pathspec, parso, packaging, oauthlib, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, mypy-extensions, multivolumefile, multidict, MarkupSafe, loralib, llvmlite, lazy_loader, joblib, jmespath, intel-sycl-rt, intel-openmp, intel-opencl-rt, iniconfig, idna, humanfriendly, fsspec, frozenlist, fonttools, filelock, exceptiongroup, dill, decorator, cycler, colorama, charset-normalizer, cachetools, audioread, asynctest, absl-py, yarl, Werkzeug, validators, tensorboardX, soxr, sentry-sdk, scipy, requests, python-dateutil, pyarrow, platformdirs, nvidia-cudnn-cu11, numexpr, multiprocess, mkl, matplotlib-inline, kiwisolver, jedi, importlib-metadata, h5py, grpcio, google-auth, gitdb, fire, dpcpp_cpp_rt, docker-pycreds, coloredlogs, cffi, Bottleneck, async-timeout, aiosignal, torch, soundfile, scikit-learn, requests-oauthlib, pybcj, pooch, pluggy, pandas, numba, mkl-service, mkl-random, mkl-fft, matplotlib, Markdown, ipython, inflate64, huggingface-hub, GitPython, gensim, facenet-pytorch, click, botocore, attrs, wandb, transformers, torchvision, torchaudio, sacremoses, s3transfer, pytest, py7zr, librosa, ipdb, google-auth-oauthlib, face-recognition, black, bitsandbytes, aiohttp, accelerate, tensorboard, peft, boto3, pytorch-transformers, datasets, optimum\nSuccessfully installed Bottleneck-1.4.0 Brotli-1.1.0 GitPython-3.1.31 Markdown-3.4.1 MarkupSafe-2.1.1 Pillow-9.0.1 PyYAML-6.0 Pygments-2.13.0 Werkzeug-2.2.2 absl-py-1.3.0 accelerate-0.20.3 aiohttp-3.8.6 aiosignal-1.3.1 appdirs-1.4.4 async-timeout-4.0.3 asynctest-0.13.0 attrs-23.1.0 audioread-3.0.1 backcall-0.2.0 bitsandbytes-0.43.3 black-23.3.0 boto3-1.21.37 botocore-1.24.37 cachetools-5.2.0 certifi-2021.10.8 cffi-1.15.1 charset-normalizer-2.0.12 click-8.1.2 cmake-3.22.3 colorama-0.4.5 coloredlogs-15.0.1 cycler-0.11.0 datasets-2.13.2 decorator-5.1.1 dill-0.3.6 dlib-19.23.1 docker-pycreds-0.4.0 dpcpp_cpp_rt-2024.2.1 exceptiongroup-1.1.3 face-recognition-1.2.3 face-recognition-models-0.3.0 facenet-pytorch-0.4.0 filelock-3.6.0 fire-0.5.0 fonttools-4.38.0 frozenlist-1.3.3 fsspec-2023.1.0 gensim-4.2.0 gitdb-4.0.10 google-auth-2.13.0 google-auth-oauthlib-0.4.6 grpcio-1.50.0 h5py-3.7.0 huggingface-hub-0.16.4 humanfriendly-10.0 idna-3.3 importlib-metadata-4.11.3 inflate64-0.3.1 iniconfig-2.0.0 intel-cmplr-lib-rt-2024.2.1 intel-cmplr-lib-ur-2024.2.1 intel-cmplr-lic-rt-2024.2.1 intel-opencl-rt-2024.2.1 intel-openmp-2024.2.1 intel-sycl-rt-2024.2.1 ipdb-0.13.9 ipython-7.34.0 jedi-0.18.1 jmespath-1.0.0 joblib-1.1.0 kiwisolver-1.4.4 lazy_loader-0.3 librosa-0.10.1 llvmlite-0.39.1 loralib-0.1.2 matplotlib-3.5.3 matplotlib-inline-0.1.6 mkl-2024.2.2 mkl-fft-1.3.1 mkl-random-1.2.2 mkl-service-2.4.0 mpmath-1.3.0 msgpack-1.0.5 multidict-6.0.4 multiprocess-0.70.14 multivolumefile-0.2.3 mypy-extensions-1.0.0 numba-0.56.4 numexpr-2.8.6 numpy-1.21.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-ml-py-11.515.0 oauthlib-3.2.2 optimum-1.14.0 packaging-23.2 pandas-1.3.4 parso-0.8.3 pathspec-0.11.2 pathtools-0.1.2 peft-0.3.0 pexpect-4.8.0 pickleshare-0.7.5 platformdirs-4.0.0 pluggy-1.2.0 pooch-1.8.0 prompt-toolkit-3.0.31 protobuf-3.19.6 psutil-5.9.4 ptyprocess-0.7.0 py7zr-0.20.6 pyarrow-12.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pybcj-1.0.1 pycparser-2.21 pycryptodomex-3.19.0 pyparsing-3.0.9 pyppmd-1.0.0 pytest-7.4.3 python-dateutil-2.9.0.post0 pytorch-transformers-1.0.0 pytz-2022.1 pyzstd-0.15.9 regex-2022.3.15 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 s3transfer-0.5.2 sacremoses-0.0.49 safetensors-0.4.0 scikit-learn-0.21.3 scipy-1.3.1 sentencepiece-0.1.96 sentry-sdk-1.16.0 setproctitle-1.3.2 six-1.17.0 smart-open-6.0.0 smmap-5.0.0 soundfile-0.12.1 soxr-0.3.7 sympy-1.10.1 tbb-2021.13.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-2.5.1 termcolor-2.3.0 texttable-1.7.0 tokenize-rt-5.0.0 tokenizers-0.13.3 toml-0.10.2 tomli-2.0.1 torch-1.13.1 torchaudio-0.13.1 torchvision-0.14.1 tqdm-4.64.1 traitlets-5.4.0 transformers-4.30.2 typed-ast-1.5.5 typing_extensions-4.7.1 urllib3-1.26.14 validators-0.20.0 wandb-0.13.10 wcwidth-0.2.5 xxhash-3.4.1 yarl-1.9.2 zipp-3.8.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!source activate MMA && python main.py --dataset mosi \\\n--data_path /kaggle/input/cmu-mosi/aligned_50.pkl \\\n--bert_path google-bert/bert-base-uncased","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-08-20T13:36:18.554623Z","iopub.execute_input":"2025-08-20T13:36:18.555068Z","iopub.status.idle":"2025-08-20T13:44:10.536509Z","shell.execute_reply.started":"2025-08-20T13:36:18.555022Z","shell.execute_reply":"2025-08-20T13:44:10.535353Z"}},"outputs":[{"name":"stdout","text":"Start loading the data....\nDownloading vocab.txt: 232kB [00:00, 25.1MB/s]\nDownloading tokenizer_config.json: 100%|█████| 48.0/48.0 [00:00<00:00, 5.03kB/s]\nDownloading config.json: 100%|█████████████████| 570/570 [00:00<00:00, 71.9kB/s]\nDownloading model.safetensors: 100%|██████████| 440M/440M [00:02<00:00, 182MB/s]\nSome weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing XBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n- This IS expected if you are initializing XBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XBertModel were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['bert.encoder.layer.9.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.10.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_2.down_proj.weight', 'bert.encoder.layer.3.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_1.up_proj.bias', 'bert.encoder.layer.4.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_vision_2.scale', 'bert.encoder.layer.1.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.10.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.5.adapter_atten_gate.out.bias', 'bert.encoder.layer.2.adapter_2.up_proj.bias', 'bert.encoder.layer.0.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.4.adapter_conv_audio.weight', 'bert.encoder.layer.8.adapter_conv_vision.bias', 'bert.encoder.layer.5.adapter_conv_vision.weight', 'bert.encoder.layer.7.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_audio_2.scale', 'bert.encoder.layer.5.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.1.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.5.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.5.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.5.adapter_audio_2.scale', 'bert.encoder.layer.6.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.11.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.9.adapter_conv_vision.bias', 'bert.encoder.layer.10.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_audio_1.scale', 'bert.encoder.layer.4.adapter_2.scale', 'bert.encoder.layer.1.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.11.adapter_vision_2.scale', 'bert.encoder.layer.4.adapter_1.up_proj.weight', 'bert.encoder.layer.0.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.6.adapter_conv_vision.bias', 'bert.encoder.layer.1.adapter_conv_vision.bias', 'bert.encoder.layer.10.adapter_conv_vision.weight', 'bert.encoder.layer.7.adapter_2.up_proj.bias', 'bert.encoder.layer.10.adapter_conv_audio.weight', 'bert.encoder.layer.4.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.2.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.9.adapter_2.down_proj.weight', 'bert.encoder.layer.7.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_conv_audio.bias', 'bert.encoder.layer.2.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_audio_1.scale', 'bert.encoder.layer.9.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_1.down_proj.weight', 'bert.encoder.layer.10.adapter_2.up_proj.weight', 'bert.encoder.layer.1.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.10.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.3.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_2.up_proj.bias', 'bert.encoder.layer.0.adapter_2.scale', 'bert.encoder.layer.11.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.10.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_1.down_proj.weight', 'bert.encoder.layer.8.adapter_conv_audio.bias', 'bert.encoder.layer.7.adapter_1.down_proj.weight', 'bert.encoder.layer.11.adapter_1.down_proj.weight', 'bert.encoder.layer.4.adapter_audio_1.scale', 'bert.encoder.layer.5.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.5.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.10.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_2.down_proj.bias', 'bert.encoder.layer.0.adapter_atten_gate.out.weight', 'bert.encoder.layer.1.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.4.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.10.adapter_1.scale', 'bert.encoder.layer.3.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.8.adapter_atten_gate.out.weight', 'bert.encoder.layer.0.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.2.adapter_conv_vision.weight', 'bert.encoder.layer.1.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.10.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.5.adapter_vision_2.scale', 'bert.encoder.layer.8.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.10.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.6.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.8.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.8.adapter_vision_1.scale', 'bert.encoder.layer.9.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.1.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.10.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.3.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.2.adapter_conv_vision.bias', 'bert.encoder.layer.5.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.8.adapter_2.down_proj.bias', 'bert.encoder.layer.6.adapter_conv_vision.weight', 'bert.encoder.layer.2.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_atten_gate.out.weight', 'bert.encoder.layer.8.adapter_conv_audio.weight', 'bert.encoder.layer.10.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.5.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.6.adapter_conv_audio.bias', 'bert.encoder.layer.4.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_2.scale', 'bert.encoder.layer.10.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_audio_1.scale', 'bert.encoder.layer.2.adapter_2.down_proj.weight', 'bert.encoder.layer.2.adapter_1.down_proj.weight', 'bert.encoder.layer.5.adapter_2.down_proj.weight', 'bert.encoder.layer.11.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.1.adapter_vision_1.scale', 'bert.encoder.layer.0.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.1.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.5.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.7.adapter_2.up_proj.weight', 'bert.encoder.layer.2.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.3.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.5.adapter_conv_vision.bias', 'bert.encoder.layer.5.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.3.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.9.adapter_conv_audio.bias', 'bert.encoder.layer.5.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.5.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.5.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.3.adapter_conv_audio.weight', 'bert.encoder.layer.6.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.5.adapter_2.up_proj.bias', 'bert.encoder.layer.1.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.4.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.7.adapter_audio_1.scale', 'bert.encoder.layer.0.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.2.adapter_conv_audio.bias', 'bert.encoder.layer.6.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_atten_gate.out.bias', 'bert.encoder.layer.8.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.11.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.5.adapter_1.scale', 'bert.encoder.layer.7.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.1.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_2.down_proj.weight', 'bert.encoder.layer.2.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.4.adapter_1.down_proj.bias', 'bert.encoder.layer.6.adapter_vision_2.scale', 'bert.encoder.layer.10.adapter_conv_audio.bias', 'bert.encoder.layer.1.adapter_atten_gate.out.bias', 'bert.encoder.layer.1.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.10.adapter_1.down_proj.weight', 'bert.encoder.layer.11.adapter_audio_1.scale', 'bert.encoder.layer.7.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.6.adapter_atten_gate.out.bias', 'bert.encoder.layer.4.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.2.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.8.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_conv_audio.weight', 'bert.encoder.layer.2.adapter_audio_1.scale', 'bert.encoder.layer.1.adapter_audio_1.scale', 'bert.encoder.layer.11.adapter_conv_vision.bias', 'bert.encoder.layer.1.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.9.adapter_2.down_proj.bias', 'bert.encoder.layer.10.adapter_1.up_proj.weight', 'bert.encoder.layer.2.adapter_1.up_proj.bias', 'bert.encoder.layer.7.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_2.down_proj.weight', 'bert.encoder.layer.4.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.0.adapter_1.up_proj.weight', 'bert.encoder.layer.4.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.6.adapter_1.down_proj.bias', 'bert.encoder.layer.10.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_atten_gate.out.weight', 'bert.encoder.layer.3.adapter_1.scale', 'bert.encoder.layer.0.adapter_1.up_proj.bias', 'bert.encoder.layer.10.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_audio_2.scale', 'bert.encoder.layer.5.adapter_1.down_proj.bias', 'bert.encoder.layer.3.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.9.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.0.adapter_vision_2.scale', 'bert.encoder.layer.1.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.2.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.1.adapter_2.up_proj.bias', 'bert.encoder.layer.2.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_vision_2.scale', 'bert.encoder.layer.1.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.11.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.1.adapter_conv_audio.bias', 'bert.encoder.layer.5.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.1.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.9.adapter_2.up_proj.bias', 'bert.encoder.layer.11.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.8.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.6.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.11.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.4.adapter_2.down_proj.bias', 'bert.encoder.layer.9.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.1.adapter_2.down_proj.bias', 'bert.encoder.layer.10.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.0.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.3.adapter_1.down_proj.weight', 'bert.encoder.layer.1.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_2.up_proj.bias', 'bert.encoder.layer.0.adapter_conv_vision.bias', 'bert.encoder.layer.4.adapter_audio_2.scale', 'bert.encoder.layer.4.adapter_atten_gate.out.bias', 'bert.encoder.layer.6.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.7.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_conv_vision.weight', 'bert.encoder.layer.10.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.2.adapter_1.down_proj.bias', 'bert.encoder.layer.7.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.11.adapter_conv_audio.weight', 'bert.encoder.layer.1.adapter_1.scale', 'bert.encoder.layer.3.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.1.adapter_audio_2.scale', 'bert.encoder.layer.3.adapter_2.up_proj.weight', 'bert.encoder.layer.4.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_1.up_proj.bias', 'bert.encoder.layer.5.adapter_1.down_proj.weight', 'bert.encoder.layer.8.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.8.adapter_2.up_proj.bias', 'bert.encoder.layer.2.adapter_1.up_proj.weight', 'bert.encoder.layer.3.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.10.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_1.down_proj.bias', 'bert.encoder.layer.4.adapter_2.down_proj.weight', 'bert.encoder.layer.5.adapter_audio_1.scale', 'bert.encoder.layer.3.adapter_conv_vision.weight', 'bert.encoder.layer.0.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.2.adapter_2.up_proj.weight', 'bert.encoder.layer.10.adapter_2.up_proj.bias', 'bert.encoder.layer.6.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.2.adapter_vision_1.scale', 'bert.encoder.layer.3.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.10.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.5.adapter_2.scale', 'bert.encoder.layer.3.adapter_2.scale', 'bert.encoder.layer.4.adapter_vision_1.scale', 'bert.encoder.layer.6.adapter_1.down_proj.weight', 'bert.encoder.layer.7.adapter_conv_audio.bias', 'bert.encoder.layer.1.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.0.adapter_2.up_proj.weight', 'bert.encoder.layer.8.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.7.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_conv_audio.bias', 'bert.encoder.layer.5.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.3.adapter_1.up_proj.weight', 'bert.encoder.layer.9.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_audio_2.scale', 'bert.encoder.layer.11.adapter_1.down_proj.bias', 'bert.encoder.layer.1.adapter_conv_audio.weight', 'bert.encoder.layer.10.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.0.adapter_1.down_proj.weight', 'bert.encoder.layer.0.adapter_1.scale', 'bert.encoder.layer.10.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.8.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.5.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.11.adapter_1.up_proj.weight', 'bert.encoder.layer.5.adapter_atten_gate.out.weight', 'bert.encoder.layer.10.adapter_1.up_proj.bias', 'bert.encoder.layer.6.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_vision_1.scale', 'bert.encoder.layer.0.adapter_conv_vision.weight', 'bert.encoder.layer.5.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.4.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.10.adapter_atten_gate.out.weight', 'bert.encoder.layer.2.adapter_1.scale', 'bert.encoder.layer.8.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.7.adapter_1.scale', 'bert.encoder.layer.3.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.7.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.1.adapter_conv_vision.weight', 'bert.encoder.layer.9.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.6.adapter_2.scale', 'bert.encoder.layer.10.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.0.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.3.adapter_audio_2.scale', 'bert.encoder.layer.7.adapter_1.up_proj.weight', 'bert.encoder.layer.1.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_conv_audio.weight', 'bert.encoder.layer.8.adapter_conv_vision.weight', 'bert.encoder.layer.1.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.6.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.4.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.2.adapter_atten_gate.out.weight', 'bert.encoder.layer.11.adapter_conv_vision.weight', 'bert.encoder.layer.8.adapter_1.scale', 'bert.encoder.layer.9.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.11.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.6.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.11.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.3.adapter_atten_gate.out.bias', 'bert.encoder.layer.3.adapter_2.up_proj.bias', 'bert.encoder.layer.2.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.5.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_2.up_proj.weight', 'bert.encoder.layer.2.adapter_2.down_proj.bias', 'bert.encoder.layer.6.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.0.adapter_atten_gate.out.bias', 'bert.encoder.layer.2.adapter_conv_audio.weight', 'bert.encoder.layer.3.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_1.down_proj.weight', 'bert.encoder.layer.3.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_2.scale', 'bert.encoder.layer.4.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.5.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.9.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.8.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_1.up_proj.weight', 'bert.encoder.layer.0.adapter_2.down_proj.weight', 'bert.encoder.layer.5.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.8.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.10.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.11.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.2.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.3.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_vision_2.scale', 'bert.encoder.layer.3.adapter_2.down_proj.weight', 'bert.encoder.layer.1.adapter_1.up_proj.weight', 'bert.encoder.layer.6.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.11.adapter_atten_gate.out.bias', 'bert.encoder.layer.10.adapter_atten_gate.out.bias', 'bert.encoder.layer.7.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.5.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.11.adapter_2.up_proj.weight', 'bert.encoder.layer.0.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.6.adapter_2.up_proj.bias', 'bert.encoder.layer.9.adapter_1.up_proj.bias', 'bert.encoder.layer.0.adapter_2.down_proj.bias', 'bert.encoder.layer.11.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_2.down_proj.bias', 'bert.encoder.layer.10.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.2.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.0.adapter_conv_audio.bias', 'bert.encoder.layer.8.adapter_1.up_proj.weight', 'bert.encoder.layer.7.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.9.adapter_1.scale', 'bert.encoder.layer.6.adapter_vision_1.scale', 'bert.encoder.layer.1.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.11.adapter_2.down_proj.weight', 'bert.encoder.layer.6.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.2.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.11.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_audio_2.scale', 'bert.encoder.layer.7.adapter_1.down_proj.bias', 'bert.encoder.layer.6.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_vision_2.scale', 'bert.encoder.layer.8.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.2.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_2.scale', 'bert.encoder.layer.7.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.3.adapter_vision_1.scale', 'bert.encoder.layer.4.adapter_vision_2.scale', 'bert.encoder.layer.1.adapter_2.scale', 'bert.encoder.layer.0.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.4.adapter_1.up_proj.bias', 'bert.encoder.layer.6.adapter_2.up_proj.weight', 'bert.encoder.layer.7.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.5.adapter_1.up_proj.bias', 'bert.encoder.layer.8.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_vision_1.scale', 'bert.encoder.layer.2.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_conv_vision.weight', 'bert.encoder.layer.4.adapter_conv_vision.bias', 'bert.encoder.layer.4.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_2.up_proj.weight', 'bert.encoder.layer.9.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.1.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.10.adapter_conv_vision.bias', 'bert.encoder.layer.8.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.8.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.6.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.7.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.7.adapter_atten_gate.out.weight', 'bert.encoder.layer.3.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.9.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_audio_2.scale', 'bert.encoder.layer.9.adapter_2.up_proj.weight', 'bert.encoder.layer.7.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.10.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.9.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.4.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_1.up_proj.bias', 'bert.encoder.layer.1.adapter_vision_2.scale', 'bert.encoder.layer.7.adapter_2.scale', 'bert.encoder.layer.11.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.0.adapter_conv_audio.weight', 'bert.encoder.layer.0.adapter_vision_1.scale', 'bert.encoder.layer.3.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.4.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.3.adapter_1.up_proj.bias', 'bert.encoder.layer.11.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.2.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.11.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.9.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_vision_2.scale', 'bert.encoder.layer.8.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.0.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.9.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.9.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.0.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.6.adapter_1.scale', 'bert.encoder.layer.4.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.2.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.6.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.7.adapter_vision_1.scale', 'bert.encoder.layer.0.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.7.adapter_audio_2.scale', 'bert.encoder.layer.6.adapter_2.down_proj.bias', 'bert.encoder.layer.6.adapter_1.up_proj.weight', 'bert.encoder.layer.3.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.8.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_atten_gate.out.weight', 'bert.encoder.layer.6.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.5.adapter_vision_1.scale', 'bert.encoder.layer.11.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.3.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.10.adapter_audio_1.scale', 'bert.encoder.layer.6.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_conv_audio.bias', 'bert.encoder.layer.8.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.10.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.10.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.4.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.1.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.8.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.5.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.11.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.10.adapter_2.down_proj.weight', 'bert.encoder.layer.0.adapter_2.up_proj.bias', 'bert.encoder.layer.9.adapter_conv_audio.weight', 'bert.encoder.layer.1.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.1.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.11.adapter_1.scale', 'bert.encoder.layer.11.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.6.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.3.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_conv_audio.bias', 'bert.encoder.layer.0.adapter_audio_2.scale', 'bert.encoder.layer.6.adapter_2.down_proj.weight', 'bert.encoder.layer.9.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_1.down_proj.bias', 'bert.encoder.layer.8.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.7.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.7.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.10.adapter_1.down_proj.bias', 'bert.encoder.layer.0.adapter_audio_1.scale', 'bert.encoder.layer.0.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_1.down_proj.bias', 'bert.encoder.layer.4.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.7.adapter_conv_vision.bias', 'bert.encoder.layer.4.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.4.adapter_2.up_proj.weight', 'bert.encoder.layer.6.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_audio_2.scale', 'bert.encoder.layer.3.adapter_2.down_proj.bias', 'bert.encoder.layer.8.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.9.adapter_1.down_proj.bias', 'bert.encoder.layer.6.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.4.adapter_1.scale', 'bert.encoder.layer.9.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.11.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.3.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.8.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_1.up_proj.bias', 'bert.encoder.layer.9.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.11.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.10.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.11.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_conv_vision.bias', 'bert.encoder.layer.11.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.5.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.5.adapter_2.down_proj.bias', 'bert.encoder.layer.5.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.8.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.2.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.11.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.2.adapter_atten_gate.out.bias', 'bert.encoder.layer.6.adapter_audio_1.scale', 'bert.encoder.layer.8.adapter_atten_gate.out.bias', 'bert.encoder.layer.10.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.2.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_2.scale', 'bert.encoder.layer.5.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.1.adapter_1.down_proj.weight', 'bert.encoder.layer.3.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.0.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_atten_gate.out.bias', 'bert.encoder.layer.9.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.10.adapter_2.down_proj.bias', 'bert.encoder.layer.3.adapter_atten_gate.out.weight', 'bert.encoder.layer.7.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.2.adapter_2.scale', 'bert.encoder.layer.11.adapter_1.up_proj.bias', 'bert.encoder.layer.6.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_1.down_proj.bias', 'bert.encoder.layer.1.adapter_2.up_proj.weight', 'bert.encoder.layer.9.adapter_conv_vision.weight', 'bert.encoder.layer.9.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.2.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_atten_gate.out.weight', 'bert.encoder.layer.7.adapter_conv_audio.weight', 'bert.encoder.layer.2.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.6.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.6.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_vision_2.scale', 'bert.encoder.layer.9.adapter_atten_gate.out.weight', 'bert.encoder.layer.7.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.0.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_1.up_proj.weight', 'bert.encoder.layer.9.adapter_vision_1.scale', 'bert.encoder.layer.4.adapter_2.adapter_layer_norm_before.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\ntrainable params: 5,730,017 || all params: 115,212,257 || trainable%: 4.9734439279320775\n--------------------------------------------------\nEpoch  1 | Time 21.6435 sec | Valid Loss 1.0850 | Test Loss 1.2071\n--------------------------------------------------\nMAE:  1.2071196\nCorrelation Coefficient:  0.7064194589685452\nmult_acc_7:  0.24635568513119532\nmult_acc_5:  0.336734693877551\nF1 score all/non0: 0.7651/0.775 over 686/656\nAccuracy all/non0: 0.7653/0.7744\n--------------------------------------------------\n--------------------------------------------------\nEpoch  2 | Time 20.7027 sec | Valid Loss 0.8895 | Test Loss 1.0183\n--------------------------------------------------\nMAE:  1.0183328\nCorrelation Coefficient:  0.7544850696112149\nmult_acc_7:  0.29591836734693877\nmult_acc_5:  0.3629737609329446\nF1 score all/non0: 0.7862/0.7984 over 686/656\nAccuracy all/non0: 0.7857/0.7973\n--------------------------------------------------\n--------------------------------------------------\nEpoch  3 | Time 20.7209 sec | Valid Loss 0.8198 | Test Loss 0.7471\n--------------------------------------------------\nMAE:  0.74707264\nCorrelation Coefficient:  0.7771866019597383\nmult_acc_7:  0.4402332361516035\nmult_acc_5:  0.5029154518950437\nF1 score all/non0: 0.8189/0.8438 over 686/656\nAccuracy all/non0: 0.8222/0.846\n--------------------------------------------------\n--------------------------------------------------\nEpoch  4 | Time 20.6834 sec | Valid Loss 0.7962 | Test Loss 0.9013\n--------------------------------------------------\nMAE:  0.9013047\nCorrelation Coefficient:  0.7478489144359354\nmult_acc_7:  0.380466472303207\nmult_acc_5:  0.4489795918367347\nF1 score all/non0: 0.796/0.8041 over 686/656\nAccuracy all/non0: 0.7959/0.8034\n--------------------------------------------------\n--------------------------------------------------\nEpoch  5 | Time 20.6595 sec | Valid Loss 0.8173 | Test Loss 0.7225\n--------------------------------------------------\n--------------------------------------------------\nEpoch  6 | Time 20.6907 sec | Valid Loss 0.7571 | Test Loss 0.8110\n--------------------------------------------------\nMAE:  0.8109795\nCorrelation Coefficient:  0.7866243271095756\nmult_acc_7:  0.4110787172011662\nmult_acc_5:  0.46355685131195334\nF1 score all/non0: 0.8327/0.8453 over 686/656\nAccuracy all/non0: 0.8324/0.8445\n--------------------------------------------------\n--------------------------------------------------\nEpoch  7 | Time 20.6373 sec | Valid Loss 0.7748 | Test Loss 0.8502\n--------------------------------------------------\n--------------------------------------------------\nEpoch  8 | Time 20.6787 sec | Valid Loss 0.7540 | Test Loss 0.7436\n--------------------------------------------------\nMAE:  0.74361897\nCorrelation Coefficient:  0.7794293082467237\nmult_acc_7:  0.4227405247813411\nmult_acc_5:  0.4897959183673469\nF1 score all/non0: 0.795/0.8244 over 686/656\nAccuracy all/non0: 0.8017/0.8293\n--------------------------------------------------\n--------------------------------------------------\nEpoch  9 | Time 20.7173 sec | Valid Loss 0.7994 | Test Loss 0.7829\n--------------------------------------------------\n--------------------------------------------------\nEpoch 10 | Time 20.6801 sec | Valid Loss 0.7302 | Test Loss 0.7283\n--------------------------------------------------\nMAE:  0.7282883\nCorrelation Coefficient:  0.795555259946086\nmult_acc_7:  0.46938775510204084\nmult_acc_5:  0.5481049562682215\nF1 score all/non0: 0.834/0.8513 over 686/656\nAccuracy all/non0: 0.8338/0.8506\n--------------------------------------------------\n--------------------------------------------------\nEpoch 11 | Time 20.7678 sec | Valid Loss 0.7182 | Test Loss 0.6962\n--------------------------------------------------\nMAE:  0.6962378\nCorrelation Coefficient:  0.7950336906592742\nmult_acc_7:  0.4752186588921283\nmult_acc_5:  0.5510204081632653\nF1 score all/non0: 0.8324/0.8496 over 686/656\nAccuracy all/non0: 0.8324/0.8491\n--------------------------------------------------\n--------------------------------------------------\nEpoch 12 | Time 20.7174 sec | Valid Loss 0.7131 | Test Loss 0.6942\n--------------------------------------------------\nMAE:  0.69420546\nCorrelation Coefficient:  0.7962192497534759\nmult_acc_7:  0.49271137026239065\nmult_acc_5:  0.5626822157434402\nF1 score all/non0: 0.8226/0.8458 over 686/656\nAccuracy all/non0: 0.8236/0.846\n--------------------------------------------------\n--------------------------------------------------\nEpoch 13 | Time 20.6488 sec | Valid Loss 0.7191 | Test Loss 0.6996\n--------------------------------------------------\n--------------------------------------------------\nEpoch 14 | Time 20.6084 sec | Valid Loss 0.7185 | Test Loss 0.7009\n--------------------------------------------------\n--------------------------------------------------\nEpoch 15 | Time 20.6796 sec | Valid Loss 0.7178 | Test Loss 0.7018\n--------------------------------------------------\n--------------------------------------------------\nEpoch 16 | Time 20.6921 sec | Valid Loss 0.7171 | Test Loss 0.6933\n--------------------------------------------------\n--------------------------------------------------\nEpoch 17 | Time 20.7054 sec | Valid Loss 0.7181 | Test Loss 0.7111\n--------------------------------------------------\n--------------------------------------------------\nEpoch 18 | Time 20.6255 sec | Valid Loss 0.7145 | Test Loss 0.7057\n--------------------------------------------------\n--------------------------------------------------\nEpoch 19 | Time 20.7792 sec | Valid Loss 0.7142 | Test Loss 0.7066\n--------------------------------------------------\n--------------------------------------------------\nEpoch 20 | Time 20.7367 sec | Valid Loss 0.7141 | Test Loss 0.7070\n--------------------------------------------------\n--------------------------------------------------\nEpoch 21 | Time 20.6832 sec | Valid Loss 0.7139 | Test Loss 0.7067\n--------------------------------------------------\n--------------------------------------------------\nEpoch 22 | Time 20.7255 sec | Valid Loss 0.7134 | Test Loss 0.7026\n--------------------------------------------------\nMAE:  0.69420546\nCorrelation Coefficient:  0.7962192497534759\nmult_acc_7:  0.49271137026239065\nmult_acc_5:  0.5626822157434402\nF1 score all/non0: 0.8226/0.8458 over 686/656\nAccuracy all/non0: 0.8236/0.846\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!source activate MMA && python main.py --dataset mosei \\\n--data_path /kaggle/input/cmu-mosei/aligned_50.pkl \\\n--bert_path google-bert/bert-base-uncased \\\n--lr_main 2e-4 --lr_lora 2e-4 --lr_adapter 2e-4 --optim Adam \\\n--audio_dim 74 --vision_dim 35","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-08-20T13:44:10.538619Z","iopub.execute_input":"2025-08-20T13:44:10.538933Z","iopub.status.idle":"2025-08-20T15:19:32.489015Z","shell.execute_reply.started":"2025-08-20T13:44:10.538900Z","shell.execute_reply":"2025-08-20T15:19:32.487906Z"}},"outputs":[{"name":"stdout","text":"Start loading the data....\nSome weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing XBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing XBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XBertModel were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['bert.encoder.layer.5.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.3.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.7.adapter_audio_2.scale', 'bert.encoder.layer.10.adapter_audio_2.scale', 'bert.encoder.layer.1.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.6.adapter_vision_2.scale', 'bert.encoder.layer.8.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.2.adapter_2.down_proj.bias', 'bert.encoder.layer.3.adapter_audio_1.scale', 'bert.encoder.layer.1.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.0.adapter_atten_gate.out.bias', 'bert.encoder.layer.2.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.7.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.1.adapter_2.down_proj.bias', 'bert.encoder.layer.11.adapter_conv_vision.weight', 'bert.encoder.layer.1.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.5.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.6.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.4.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_conv_vision.weight', 'bert.encoder.layer.0.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.7.adapter_atten_gate.out.weight', 'bert.encoder.layer.8.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.10.adapter_2.up_proj.bias', 'bert.encoder.layer.10.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.6.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.6.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.5.adapter_2.up_proj.bias', 'bert.encoder.layer.7.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_1.down_proj.weight', 'bert.encoder.layer.9.adapter_1.up_proj.weight', 'bert.encoder.layer.10.adapter_1.scale', 'bert.encoder.layer.10.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.8.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.4.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.7.adapter_vision_1.scale', 'bert.encoder.layer.10.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.8.adapter_2.up_proj.weight', 'bert.encoder.layer.9.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.9.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.0.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_conv_audio.bias', 'bert.encoder.layer.1.adapter_conv_vision.bias', 'bert.encoder.layer.1.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.1.adapter_conv_audio.bias', 'bert.encoder.layer.1.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_conv_audio.bias', 'bert.encoder.layer.7.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.4.adapter_2.up_proj.weight', 'bert.encoder.layer.4.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.10.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.6.adapter_2.up_proj.bias', 'bert.encoder.layer.5.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.7.adapter_atten_gate.out.bias', 'bert.encoder.layer.6.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.10.adapter_conv_vision.bias', 'bert.encoder.layer.5.adapter_1.up_proj.bias', 'bert.encoder.layer.10.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.3.adapter_2.scale', 'bert.encoder.layer.9.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.1.adapter_audio_2.scale', 'bert.encoder.layer.3.adapter_atten_gate.out.weight', 'bert.encoder.layer.0.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.11.adapter_1.up_proj.weight', 'bert.encoder.layer.9.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.3.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_2.down_proj.bias', 'bert.encoder.layer.0.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.0.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.9.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.4.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.11.adapter_2.down_proj.bias', 'bert.encoder.layer.1.adapter_conv_audio.weight', 'bert.encoder.layer.6.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.2.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_atten_gate.out.weight', 'bert.encoder.layer.10.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_2.up_proj.bias', 'bert.encoder.layer.10.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.0.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_conv_audio.bias', 'bert.encoder.layer.4.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.6.adapter_atten_gate.out.bias', 'bert.encoder.layer.3.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_1.down_proj.weight', 'bert.encoder.layer.5.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.2.adapter_vision_2.scale', 'bert.encoder.layer.2.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_atten_gate.out.weight', 'bert.encoder.layer.2.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.6.adapter_audio_1.scale', 'bert.encoder.layer.4.adapter_1.down_proj.weight', 'bert.encoder.layer.4.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.11.adapter_conv_audio.weight', 'bert.encoder.layer.11.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.0.adapter_2.scale', 'bert.encoder.layer.6.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.8.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_1.scale', 'bert.encoder.layer.10.adapter_1.up_proj.weight', 'bert.encoder.layer.3.adapter_2.up_proj.weight', 'bert.encoder.layer.8.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.2.adapter_2.up_proj.bias', 'bert.encoder.layer.11.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.8.adapter_atten_gate.out.weight', 'bert.encoder.layer.11.adapter_vision_1.scale', 'bert.encoder.layer.5.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.5.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_audio_1.scale', 'bert.encoder.layer.2.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.8.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.11.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_2.scale', 'bert.encoder.layer.10.adapter_2.down_proj.bias', 'bert.encoder.layer.9.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.10.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.3.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.1.adapter_atten_gate.out.bias', 'bert.encoder.layer.9.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.2.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.6.adapter_1.down_proj.bias', 'bert.encoder.layer.11.adapter_audio_2.scale', 'bert.encoder.layer.4.adapter_1.up_proj.weight', 'bert.encoder.layer.1.adapter_vision_2.scale', 'bert.encoder.layer.11.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.4.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.8.adapter_1.down_proj.bias', 'bert.encoder.layer.0.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.0.adapter_1.down_proj.bias', 'bert.encoder.layer.3.adapter_2.down_proj.weight', 'bert.encoder.layer.10.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.2.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.0.adapter_conv_audio.weight', 'bert.encoder.layer.2.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_2.down_proj.weight', 'bert.encoder.layer.4.adapter_conv_audio.weight', 'bert.encoder.layer.10.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.6.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.6.adapter_2.up_proj.weight', 'bert.encoder.layer.8.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.0.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.6.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_conv_vision.weight', 'bert.encoder.layer.11.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.5.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.2.adapter_audio_1.scale', 'bert.encoder.layer.2.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.5.adapter_1.scale', 'bert.encoder.layer.11.adapter_conv_vision.bias', 'bert.encoder.layer.3.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.9.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.10.adapter_conv_audio.bias', 'bert.encoder.layer.5.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_vision_2.scale', 'bert.encoder.layer.6.adapter_2.scale', 'bert.encoder.layer.7.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.0.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.1.adapter_conv_vision.weight', 'bert.encoder.layer.3.adapter_1.down_proj.bias', 'bert.encoder.layer.3.adapter_2.down_proj.bias', 'bert.encoder.layer.8.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_conv_audio.bias', 'bert.encoder.layer.5.adapter_conv_audio.weight', 'bert.encoder.layer.9.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.11.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.2.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_vision_1.scale', 'bert.encoder.layer.8.adapter_conv_audio.bias', 'bert.encoder.layer.8.adapter_2.up_proj.bias', 'bert.encoder.layer.8.adapter_conv_vision.weight', 'bert.encoder.layer.10.adapter_1.up_proj.bias', 'bert.encoder.layer.3.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.9.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.1.adapter_2.down_proj.weight', 'bert.encoder.layer.9.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.11.adapter_2.down_proj.weight', 'bert.encoder.layer.2.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.7.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.6.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.8.adapter_audio_2.scale', 'bert.encoder.layer.11.adapter_1.up_proj.bias', 'bert.encoder.layer.11.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.7.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.9.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.8.adapter_vision_1.scale', 'bert.encoder.layer.3.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.6.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.2.adapter_2.up_proj.weight', 'bert.encoder.layer.8.adapter_conv_audio.weight', 'bert.encoder.layer.8.adapter_1.up_proj.bias', 'bert.encoder.layer.2.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.1.adapter_2.up_proj.bias', 'bert.encoder.layer.8.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.10.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.0.adapter_conv_vision.weight', 'bert.encoder.layer.0.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.1.adapter_1.up_proj.bias', 'bert.encoder.layer.1.adapter_1.down_proj.bias', 'bert.encoder.layer.6.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.0.adapter_atten_gate.out.weight', 'bert.encoder.layer.11.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.6.adapter_1.scale', 'bert.encoder.layer.0.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.5.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_vision_2.scale', 'bert.encoder.layer.0.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.6.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.3.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.0.adapter_vision_2.scale', 'bert.encoder.layer.5.adapter_vision_1.scale', 'bert.encoder.layer.10.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.0.adapter_vision_1.scale', 'bert.encoder.layer.1.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.6.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.7.adapter_1.up_proj.bias', 'bert.encoder.layer.10.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_1.scale', 'bert.encoder.layer.3.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_1.down_proj.weight', 'bert.encoder.layer.10.adapter_audio_1.scale', 'bert.encoder.layer.9.adapter_1.down_proj.bias', 'bert.encoder.layer.11.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.3.adapter_1.up_proj.bias', 'bert.encoder.layer.5.adapter_1.down_proj.weight', 'bert.encoder.layer.8.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.11.adapter_2.up_proj.weight', 'bert.encoder.layer.11.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.0.adapter_audio_1.scale', 'bert.encoder.layer.1.adapter_1.down_proj.weight', 'bert.encoder.layer.10.adapter_atten_gate.out.weight', 'bert.encoder.layer.7.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_audio_2.scale', 'bert.encoder.layer.9.adapter_1.scale', 'bert.encoder.layer.9.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.0.adapter_1.up_proj.bias', 'bert.encoder.layer.10.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.4.adapter_vision_2.scale', 'bert.encoder.layer.10.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.0.adapter_2.up_proj.bias', 'bert.encoder.layer.1.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.6.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.10.adapter_2.up_proj.weight', 'bert.encoder.layer.1.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.7.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.9.adapter_vision_1.scale', 'bert.encoder.layer.11.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.9.adapter_conv_vision.bias', 'bert.encoder.layer.3.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.7.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.3.adapter_atten_gate.out.bias', 'bert.encoder.layer.4.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.4.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.8.adapter_2.scale', 'bert.encoder.layer.7.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.10.adapter_conv_vision.weight', 'bert.encoder.layer.1.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.4.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_1.down_proj.weight', 'bert.encoder.layer.9.adapter_2.scale', 'bert.encoder.layer.0.adapter_1.scale', 'bert.encoder.layer.6.adapter_audio_2.scale', 'bert.encoder.layer.4.adapter_2.up_proj.bias', 'bert.encoder.layer.9.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.4.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.2.adapter_vision_1.scale', 'bert.encoder.layer.1.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_conv_audio.bias', 'bert.encoder.layer.6.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.8.adapter_conv_vision.bias', 'bert.encoder.layer.7.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.4.adapter_1.down_proj.bias', 'bert.encoder.layer.8.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.1.adapter_vision_1.scale', 'bert.encoder.layer.1.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.11.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.5.adapter_1.up_proj.weight', 'bert.encoder.layer.10.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_2.up_proj.bias', 'bert.encoder.layer.4.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_2.up_proj.weight', 'bert.encoder.layer.9.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.3.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.10.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_2.down_proj.weight', 'bert.encoder.layer.4.adapter_atten_gate.out.weight', 'bert.encoder.layer.0.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.8.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_1.up_proj.weight', 'bert.encoder.layer.7.adapter_2.up_proj.weight', 'bert.encoder.layer.6.adapter_conv_audio.bias', 'bert.encoder.layer.11.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_conv_vision.weight', 'bert.encoder.layer.9.adapter_1.up_proj.bias', 'bert.encoder.layer.10.adapter_vision_1.scale', 'bert.encoder.layer.6.adapter_2.down_proj.bias', 'bert.encoder.layer.2.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.9.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_conv_vision.weight', 'bert.encoder.layer.7.adapter_conv_audio.weight', 'bert.encoder.layer.5.adapter_vision_2.scale', 'bert.encoder.layer.7.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.4.adapter_conv_vision.weight', 'bert.encoder.layer.7.adapter_audio_1.scale', 'bert.encoder.layer.4.adapter_conv_vision.bias', 'bert.encoder.layer.2.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.1.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.0.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_audio_1.scale', 'bert.encoder.layer.5.adapter_conv_vision.bias', 'bert.encoder.layer.3.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.6.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.5.adapter_audio_1.scale', 'bert.encoder.layer.8.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.10.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_conv_vision.bias', 'bert.encoder.layer.6.adapter_vision_1.scale', 'bert.encoder.layer.2.adapter_2.down_proj.weight', 'bert.encoder.layer.1.adapter_1.scale', 'bert.encoder.layer.3.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.5.adapter_conv_vision.weight', 'bert.encoder.layer.5.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.0.adapter_2.down_proj.bias', 'bert.encoder.layer.8.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.4.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.6.adapter_conv_audio.weight', 'bert.encoder.layer.9.adapter_conv_audio.bias', 'bert.encoder.layer.0.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.2.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.10.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.11.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.2.adapter_1.down_proj.weight', 'bert.encoder.layer.11.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_1.up_proj.bias', 'bert.encoder.layer.7.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.7.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.6.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_2.up_proj.weight', 'bert.encoder.layer.9.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_1.down_proj.weight', 'bert.encoder.layer.8.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.1.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.9.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.1.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.8.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.1.adapter_audio_1.scale', 'bert.encoder.layer.0.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.7.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_2.up_proj.weight', 'bert.encoder.layer.2.adapter_1.down_proj.bias', 'bert.encoder.layer.4.adapter_2.scale', 'bert.encoder.layer.11.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.5.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.5.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.5.adapter_atten_gate.out.bias', 'bert.encoder.layer.3.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.3.adapter_vision_2.scale', 'bert.encoder.layer.7.adapter_conv_audio.bias', 'bert.encoder.layer.5.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.2.adapter_1.up_proj.bias', 'bert.encoder.layer.7.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.4.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.5.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.10.adapter_1.down_proj.weight', 'bert.encoder.layer.8.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.1.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_2.down_proj.bias', 'bert.encoder.layer.10.adapter_conv_audio.weight', 'bert.encoder.layer.3.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.9.adapter_1.down_proj.weight', 'bert.encoder.layer.2.adapter_conv_vision.bias', 'bert.encoder.layer.6.adapter_1.up_proj.bias', 'bert.encoder.layer.1.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.0.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.9.adapter_conv_vision.weight', 'bert.encoder.layer.11.adapter_atten_gate.out.weight', 'bert.encoder.layer.7.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_conv_audio.bias', 'bert.encoder.layer.9.adapter_audio_2.scale', 'bert.encoder.layer.0.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.2.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.7.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.4.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.2.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.2.adapter_1.scale', 'bert.encoder.layer.5.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.3.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.1.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_conv_vision.bias', 'bert.encoder.layer.4.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.8.adapter_2.down_proj.weight', 'bert.encoder.layer.8.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.3.adapter_vision_2.up_proj.bias', 'bert.encoder.layer.11.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.8.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.3.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.6.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.9.adapter_atten_gate.out.bias', 'bert.encoder.layer.11.adapter_1.down_proj.bias', 'bert.encoder.layer.9.adapter_vision_2.scale', 'bert.encoder.layer.10.adapter_vision_2.scale', 'bert.encoder.layer.1.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.7.adapter_vision_2.scale', 'bert.encoder.layer.10.adapter_2.scale', 'bert.encoder.layer.1.adapter_audio_1.down_proj.bias', 'bert.encoder.layer.2.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.0.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_vision_1.up_proj.bias', 'bert.encoder.layer.8.adapter_1.up_proj.weight', 'bert.encoder.layer.11.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.4.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.5.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.5.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.10.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_vision_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.4.adapter_atten_gate.out.bias', 'bert.encoder.layer.3.adapter_vision_1.scale', 'bert.encoder.layer.5.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.5.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.5.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.3.adapter_conv_audio.weight', 'bert.encoder.layer.6.adapter_2.down_proj.weight', 'bert.encoder.layer.10.adapter_atten_gate.out.bias', 'bert.encoder.layer.2.adapter_atten_gate.out.weight', 'bert.encoder.layer.7.adapter_2.up_proj.bias', 'bert.encoder.layer.3.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.5.adapter_atten_gate.out.weight', 'bert.encoder.layer.2.adapter_1.up_proj.weight', 'bert.encoder.layer.6.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.1.adapter_vision_1.down_proj.bias', 'bert.encoder.layer.2.adapter_vision_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.6.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.9.adapter_2.down_proj.bias', 'bert.encoder.layer.7.adapter_1.down_proj.bias', 'bert.encoder.layer.9.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_1.up_proj.weight', 'bert.encoder.layer.2.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.1.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_1.down_proj.weight', 'bert.encoder.layer.1.adapter_atten_gate.out.weight', 'bert.encoder.layer.3.adapter_2.up_proj.bias', 'bert.encoder.layer.5.adapter_2.up_proj.weight', 'bert.encoder.layer.8.adapter_audio_2.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_audio_1.scale', 'bert.encoder.layer.8.adapter_2.down_proj.bias', 'bert.encoder.layer.8.adapter_atten_gate.out.bias', 'bert.encoder.layer.2.adapter_atten_gate.out.bias', 'bert.encoder.layer.5.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.1.adapter_1.up_proj.weight', 'bert.encoder.layer.7.adapter_1.scale', 'bert.encoder.layer.3.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.7.adapter_1.up_proj.weight', 'bert.encoder.layer.6.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.5.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.3.adapter_1.up_proj.weight', 'bert.encoder.layer.9.adapter_vision_2.up_proj.weight', 'bert.encoder.layer.11.adapter_vision_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.7.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.11.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.11.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.2.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.3.adapter_audio_1.down_proj.weight', 'bert.encoder.layer.3.adapter_audio_2.scale', 'bert.encoder.layer.4.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.11.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.5.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.0.adapter_2.down_proj.weight', 'bert.encoder.layer.3.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.9.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.8.adapter_1.scale', 'bert.encoder.layer.11.adapter_audio_2.down_proj.weight', 'bert.encoder.layer.11.adapter_atten_gate.out.bias', 'bert.encoder.layer.10.adapter_vision_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.11.adapter_2.scale', 'bert.encoder.layer.6.adapter_audio_2.down_proj.bias', 'bert.encoder.layer.0.adapter_audio_2.scale', 'bert.encoder.layer.10.adapter_vision_2.down_proj.weight', 'bert.encoder.layer.1.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.5.adapter_1.down_proj.bias', 'bert.encoder.layer.6.adapter_audio_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.2.adapter_audio_2.scale', 'bert.encoder.layer.4.adapter_audio_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.0.adapter_audio_2.up_proj.weight', 'bert.encoder.layer.6.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.10.adapter_audio_1.up_proj.bias', 'bert.encoder.layer.9.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.10.adapter_audio_2.up_proj.bias', 'bert.encoder.layer.2.adapter_conv_audio.weight', 'bert.encoder.layer.3.adapter_1.scale', 'bert.encoder.layer.8.adapter_audio_1.scale', 'bert.encoder.layer.9.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.10.adapter_1.down_proj.bias', 'bert.encoder.layer.2.adapter_vision_1.down_proj.weight', 'bert.encoder.layer.9.adapter_2.down_proj.weight', 'bert.encoder.layer.6.adapter_audio_1.up_proj.weight', 'bert.encoder.layer.7.adapter_2.down_proj.bias', 'bert.encoder.layer.10.adapter_vision_2.down_proj.bias', 'bert.encoder.layer.8.adapter_vision_1.up_proj.weight', 'bert.encoder.layer.2.adapter_2.scale', 'bert.encoder.layer.6.adapter_conv_vision.bias', 'bert.encoder.layer.10.adapter_2.down_proj.weight', 'bert.encoder.layer.5.adapter_audio_2.scale', 'bert.encoder.layer.9.adapter_conv_audio.weight', 'bert.encoder.layer.4.adapter_audio_2.adapter_layer_norm_before.weight', 'bert.encoder.layer.7.adapter_1.adapter_layer_norm_before.bias', 'bert.encoder.layer.4.adapter_1.adapter_layer_norm_before.weight', 'bert.encoder.layer.0.adapter_conv_vision.bias', 'bert.encoder.layer.1.adapter_2.scale', 'bert.encoder.layer.5.adapter_2.down_proj.weight', 'bert.encoder.layer.7.adapter_2.scale', 'bert.encoder.layer.5.adapter_audio_2.up_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\ntrainable params: 8,052,449 || all params: 117,534,689 || trainable%: 6.851125457948845\n--------------------------------------------------\nEpoch  1 | Time 238.9865 sec | Valid Loss 0.5565 | Test Loss 0.5814\n--------------------------------------------------\nMAE:  0.58137935\nCorrelation Coefficient:  0.7345735229717317\nmult_acc_7:  0.5026829791800815\nmult_acc_5:  0.5209272376046362\nF1 score all/non0: 0.8212/0.8322 over 4659/3634\nAccuracy all/non0: 0.8214/0.8363\n--------------------------------------------------\n--------------------------------------------------\nEpoch  2 | Time 237.7222 sec | Valid Loss 0.5273 | Test Loss 0.5496\n--------------------------------------------------\nMAE:  0.54962593\nCorrelation Coefficient:  0.7514897381242638\nmult_acc_7:  0.532732345996995\nmult_acc_5:  0.5471131144022322\nF1 score all/non0: 0.8324/0.8515 over 4659/3634\nAccuracy all/non0: 0.8313/0.8542\n--------------------------------------------------\n--------------------------------------------------\nEpoch  3 | Time 237.7543 sec | Valid Loss 0.5205 | Test Loss 0.5460\n--------------------------------------------------\nMAE:  0.545973\nCorrelation Coefficient:  0.7560323962701163\nmult_acc_7:  0.5344494526722473\nmult_acc_5:  0.5494741360807041\nF1 score all/non0: 0.8367/0.8485 over 4659/3634\nAccuracy all/non0: 0.8367/0.8517\n--------------------------------------------------\n--------------------------------------------------\nEpoch  4 | Time 236.4695 sec | Valid Loss 0.5173 | Test Loss 0.5419\n--------------------------------------------------\nMAE:  0.5419179\nCorrelation Coefficient:  0.7603327046576115\nmult_acc_7:  0.5475423910710453\nmult_acc_5:  0.5655720111611934\nF1 score all/non0: 0.8128/0.8515 over 4659/3634\nAccuracy all/non0: 0.8068/0.8514\n--------------------------------------------------\n--------------------------------------------------\nEpoch  5 | Time 237.3463 sec | Valid Loss 0.5184 | Test Loss 0.5323\n--------------------------------------------------\n--------------------------------------------------\nEpoch  6 | Time 236.4787 sec | Valid Loss 0.5202 | Test Loss 0.5434\n--------------------------------------------------\n--------------------------------------------------\nEpoch  7 | Time 236.4687 sec | Valid Loss 0.5185 | Test Loss 0.5373\n--------------------------------------------------\n--------------------------------------------------\nEpoch  8 | Time 235.9332 sec | Valid Loss 0.5162 | Test Loss 0.5364\n--------------------------------------------------\nMAE:  0.5364123\nCorrelation Coefficient:  0.7633316590695784\nmult_acc_7:  0.5460399227301996\nmult_acc_5:  0.5623524361450956\nF1 score all/non0: 0.8092/0.846 over 4659/3634\nAccuracy all/non0: 0.8032/0.8459\n--------------------------------------------------\n--------------------------------------------------\nEpoch  9 | Time 236.8550 sec | Valid Loss 0.5118 | Test Loss 0.5315\n--------------------------------------------------\nMAE:  0.5314743\nCorrelation Coefficient:  0.7633425206687581\nmult_acc_7:  0.5423910710452887\nmult_acc_5:  0.5602060528010303\nF1 score all/non0: 0.8272/0.8589 over 4659/3634\nAccuracy all/non0: 0.8231/0.8597\n--------------------------------------------------\n--------------------------------------------------\nEpoch 10 | Time 235.8275 sec | Valid Loss 0.5082 | Test Loss 0.5316\n--------------------------------------------------\nMAE:  0.5315607\nCorrelation Coefficient:  0.7677702784806179\nmult_acc_7:  0.5473277527366388\nmult_acc_5:  0.5651427344923804\nF1 score all/non0: 0.8162/0.8538 over 4659/3634\nAccuracy all/non0: 0.8107/0.8539\n--------------------------------------------------\n--------------------------------------------------\nEpoch 11 | Time 235.6236 sec | Valid Loss 0.5083 | Test Loss 0.5325\n--------------------------------------------------\n--------------------------------------------------\nEpoch 12 | Time 236.0049 sec | Valid Loss 0.5082 | Test Loss 0.5319\n--------------------------------------------------\n--------------------------------------------------\nEpoch 13 | Time 236.6722 sec | Valid Loss 0.5073 | Test Loss 0.5304\n--------------------------------------------------\nMAE:  0.53040683\nCorrelation Coefficient:  0.7661302332001463\nmult_acc_7:  0.5462545610646061\nmult_acc_5:  0.5632109894827216\nF1 score all/non0: 0.8258/0.8557 over 4659/3634\nAccuracy all/non0: 0.8221/0.8566\n--------------------------------------------------\n--------------------------------------------------\nEpoch 14 | Time 235.3629 sec | Valid Loss 0.5072 | Test Loss 0.5306\n--------------------------------------------------\nMAE:  0.53058165\nCorrelation Coefficient:  0.7662395764760115\nmult_acc_7:  0.5479716677398584\nmult_acc_5:  0.5649280961579738\nF1 score all/non0: 0.8224/0.8564 over 4659/3634\nAccuracy all/non0: 0.8178/0.8569\n--------------------------------------------------\n--------------------------------------------------\nEpoch 15 | Time 235.7821 sec | Valid Loss 0.5115 | Test Loss 0.5347\n--------------------------------------------------\n--------------------------------------------------\nEpoch 16 | Time 235.5383 sec | Valid Loss 0.5116 | Test Loss 0.5338\n--------------------------------------------------\n--------------------------------------------------\nEpoch 17 | Time 235.3637 sec | Valid Loss 0.5135 | Test Loss 0.5358\n--------------------------------------------------\n--------------------------------------------------\nEpoch 18 | Time 235.5001 sec | Valid Loss 0.5183 | Test Loss 0.5387\n--------------------------------------------------\n--------------------------------------------------\nEpoch 19 | Time 235.6745 sec | Valid Loss 0.5134 | Test Loss 0.5344\n--------------------------------------------------\n--------------------------------------------------\nEpoch 20 | Time 235.8097 sec | Valid Loss 0.5139 | Test Loss 0.5348\n--------------------------------------------------\n--------------------------------------------------\nEpoch 21 | Time 236.8031 sec | Valid Loss 0.5137 | Test Loss 0.5346\n--------------------------------------------------\n--------------------------------------------------\nEpoch 22 | Time 236.3208 sec | Valid Loss 0.5140 | Test Loss 0.5350\n--------------------------------------------------\n--------------------------------------------------\nEpoch 23 | Time 236.9170 sec | Valid Loss 0.5144 | Test Loss 0.5353\n--------------------------------------------------\n--------------------------------------------------\nEpoch 24 | Time 235.8145 sec | Valid Loss 0.5146 | Test Loss 0.5356\n--------------------------------------------------\nMAE:  0.53058165\nCorrelation Coefficient:  0.7662395764760115\nmult_acc_7:  0.5479716677398584\nmult_acc_5:  0.5649280961579738\nF1 score all/non0: 0.8224/0.8564 over 4659/3634\nAccuracy all/non0: 0.8178/0.8569\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":6}]}